{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291f0722",
   "metadata": {},
   "source": [
    "## 8-custom-phenotypes-individual-trait-files-and-regenie -- Plan\n",
    "\n",
    "This notebook does not use tretools either to generate `individual_trait_files` or to generate `regenie` files.  Instead it uses \"pure\" polars which means tit is a lot faster and easier to \"debug\" and check.\n",
    "\n",
    "We import the ICD-10, SNOMED-CT and OPCS mapping dataframes and join these to `megadata` files.\n",
    "\n",
    "We then deduplicate and \"tidy-up\" and save one `individual_trait_file` per phenotype.\n",
    "\n",
    "We uses a non-tretools method to create both `individual_trait_file`s and the `regenie` files\n",
    "\n",
    "We discovered an issue with `GenesAndHealth_custombinary_codelist_v010_2025_05v3.csv` (non-standard characters and duplicated lines), these were corrected and now we use `GenesAndHealth_custombinary_codelist_v010_2025_05v4.csv`\n",
    "\n",
    "We have verifed that our methods and the TREtools based methods create the same output **if individuals with no assigned phenotypes (i.e. 0 out of 287 custom phenotypes assigned) are excluded**\n",
    "\n",
    "On 2025-05-23, there were 287 custom phenotypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'version010_2025_05_SR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee6da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = \"version010\"\n",
    "mon = \"05\"\n",
    "yr = \"2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0207ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from cloudpathlib import AnyPath\n",
    "from datetime import datetime\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d328737",
   "metadata": {},
   "source": [
    "### Scripting for automated next notebook initation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a8595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redirect_to_next_notebook_in_pipeline(other_notebook):\n",
    "    \n",
    "    js_code = f\"\"\"\n",
    "    if (typeof Jupyter !== 'undefined' && Jupyter.notebook && Jupyter.notebook.kernel) {{\n",
    "        // only runs when cell is executed, not from cached output\n",
    "        console.log(\"Redirecting to next notebook in pipeline...\");\n",
    "        Jupyter.notebook.save_checkpoint();\n",
    "        Jupyter.notebook.session.delete();\n",
    "        \n",
    "        setTimeout(function() {{\n",
    "            window.location.href = '{other_notebook}.ipynb';\n",
    "        }}, 1500)\n",
    "    }} else {{\n",
    "        console.log(\"Found cached output. Not an active notebook context. Skipping redirect.\")\n",
    "    }}\n",
    "    \"\"\"\n",
    "    display(Javascript(js_code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bd2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polars namespace additions\n",
    "\n",
    "# In subsequent version this code may be integrated with the establisted TRE Tools package\n",
    "\n",
    "@pl.api.register_lazyframe_namespace(\"TRE\")\n",
    "class TRETools:\n",
    "    def __init__(self, lzdf: pl.LazyFrame) -> None:\n",
    "        self._lzdf = lzdf\n",
    "        \n",
    "    def unique_with_logging(self, *args, label: str = \"Unique\", **kwargs) -> pl.LazyFrame:\n",
    "        before = self._lzdf.select(pl.first()).collect().height\n",
    "        filtered_lzdf = self._lzdf.unique(*args, **kwargs)\n",
    "        after = filtered_lzdf.select(pl.first()).collect().height\n",
    "        \n",
    "        if before > 0:\n",
    "            change = ((after - before) / before) * 100\n",
    "            change_str = f\" ({'+' if change > 0 else ''}{change:.1f}%)\"\n",
    "        \n",
    "        unchanged = \" (row count unchanged)\" if after == before else \"\"\n",
    "        \n",
    "        print(f\"[{label}: on {args}] Before unique: {before} rows, After unique: {after} rows{unchanged}{change_str}\")\n",
    "        return filtered_lzdf    \n",
    "    \n",
    "    def filter_with_logging(self, *args, label: str = \"Filter\", **kwargs) -> pl.LazyFrame:\n",
    "        before = self._lzdf.select(pl.first()).collect().height\n",
    "        filtered_lzdf = self._lzdf.filter(*args, **kwargs)\n",
    "        after = filtered_lzdf.select(pl.first()).collect().height\n",
    "        \n",
    "        if before > 0:\n",
    "            change = ((after - before) / before) * 100\n",
    "            change_str = f\" ({'+' if change > 0 else ''}{change:.1f}%)\"\n",
    "        \n",
    "        unchanged = \" (row count unchanged)\" if after == before else \"\"\n",
    "        print(f\"[{label}] Before filter: {before} rows, After filter: {after} rows{unchanged}{change_str}\")\n",
    "        return filtered_lzdf\n",
    "    \n",
    "    def join_with_logging(\n",
    "        self,\n",
    "        other: pl.LazyFrame,\n",
    "        *args,\n",
    "        how: str = \"inner\",\n",
    "        label: str = \"Join\",\n",
    "        **kwargs\n",
    "    ) -> pl.LazyFrame:\n",
    "        left_before = self._lzdf.select(pl.first()).collect().height\n",
    "        right_before = other.select(pl.first()).collect().height\n",
    "        joined_lzdf = self._lzdf.join(other, *args, how=how, **kwargs)\n",
    "        after = joined_lzdf.select(pl.first()).collect().height\n",
    "        \n",
    "        if left_before > 0:\n",
    "            change = ((after - left_before) / left_before) * 100\n",
    "            change_str = f\" ({'+' if change > 0 else ''}{change:.1f}%)\" if abs(change) > 1.00 else f\" ({after - left_before} rows {' removed' if change < 0 else ' added'})\"\n",
    "        \n",
    "        unchanged = \" (row count unchanged)\" if after == left_before else \"\"\n",
    "        print(f\"[{label}] Join type: {how.upper()}\")\n",
    "        print(f\"[{label}] Left: {left_before} rows, Right: {right_before} rows -> After: {after} rows{unchanged}{change_str}\")\n",
    "        return joined_lzdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961bef0f",
   "metadata": {},
   "source": [
    "**Paths to files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9b5748",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_LOCATION = \"/home/ivm/BI_PY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1871565a",
   "metadata": {},
   "source": [
    "#### Data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ef07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS_LOCATION = f\"{ROOT_LOCATION}/{VERSION}/inputs\"\n",
    "MEGADATA_LOCATION = f\"{ROOT_LOCATION}/{VERSION}/megadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a7245",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_CODELIST_INPUT_FILE_LOCATION = (\n",
    "    f\"{INPUTS_LOCATION}/GenesAndHealth_custombinary_codelist_v010_2025_05v4.csv\"\n",
    ")\n",
    "CUSTOM_CODELIST_INPUT_FILE_PATH = AnyPath(\n",
    "    CUSTOM_CODELIST_INPUT_FILE_LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadb46e9",
   "metadata": {},
   "source": [
    "#### Data out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc38f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS_CUSTOM_PHENOTYPES_LOCATION = f\"{ROOT_LOCATION}/{VERSION}/outputs/custom_phenotypes\"\n",
    "OUTPUTS_CUSTOM_PHENOTYPES_PATH = AnyPath(\n",
    "    OUTPUTS_CUSTOM_PHENOTYPES_LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6120fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS_CUSTOM_PHENOTYPES_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76453b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS_INDIVIDUAL_TRAIT_FILES_LOCATION = f\"{OUTPUTS_CUSTOM_PHENOTYPES_LOCATION}/individual_trait_files/\"\n",
    "\n",
    "OUTPUTS_REGENIE_FILES_LOCATION = f\"{OUTPUTS_CUSTOM_PHENOTYPES_LOCATION}/regenie/\"\n",
    "OUTPUTS_REGENIE_FILES_TEMP_LOCATION = f\"{OUTPUTS_REGENIE_FILES_LOCATION}/temp/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cdfefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnyPath(OUTPUTS_INDIVIDUAL_TRAIT_FILES_LOCATION).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AnyPath(OUTPUTS_REGENIE_FILES_LOCATION).mkdir(parents=True, exist_ok=True)\n",
    "AnyPath(OUTPUTS_REGENIE_FILES_TEMP_LOCATION).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6252df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEGA_LINKAGE_PATH = AnyPath(\n",
    "    \"/genesandhealth/library-red/genesandhealth\",\n",
    "    \"2025_02_10__MegaLinkage_forTRE.csv\" # actually tab-delimited\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f0a356",
   "metadata": {},
   "source": [
    "## Instantiate Custom Phenotype Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9cc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "coding_system_enum = pl.Enum([\"ICD10\", \"OPCS4\", \"SNOMED_ConceptID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07c8be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_phenotype_mapping = (\n",
    "    pl.scan_csv(\n",
    "        CUSTOM_CODELIST_INPUT_FILE_PATH\n",
    "    )\n",
    "    .rename({\"term\":\"coding_system\"})\n",
    "    .select(\n",
    "        pl.col(\"code\"),\n",
    "        pl.col(\"coding_system\").cast(coding_system_enum),\n",
    "        pl.col(\"phenotype\"),\n",
    "        pl.col(\"name\").alias(\"term\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e335b4c",
   "metadata": {},
   "source": [
    "**Note added by SB 2024-03-26**\n",
    "\n",
    "There appears to be a problem with the ICD codelist for phenotype `MGH_MajorAdverseVascularLimbEvent`. It has unfeasible codes in it: `0Y6N0Z5` and others. For now, I have manually removed this (sic) lines from the codelist. \n",
    "\n",
    "The MGH_CKD lists also have extra whitespaces which have been removed.\n",
    "\n",
    "**Note added by SR 2025-04-22**\n",
    "\n",
    "I cannot find any mention of `MGH_MajorAdverseVascularLimbEvent` in the large codelist.  Perhaps SB deleted all lines pertaining to `MGH_MajorAdverseVascularLimbEvent`\n",
    "\n",
    "1. We still see some non-standard white spaces in MGH_CKD, e.g. `MGH_CKD,N182<0xa0>,ICD10,\"Chronic kidney disease, stage 2\"` (\\&nbsp;)\n",
    "2. We updated the principal code list to include:  \n",
    "    a. Aniruddh Patel's updated `MGH_MajorAdverseVascularLimbEvent` code list  \n",
    "    b. Joe Gafton's Skin problem code list.  We did this by processing their files and appending the processed version to the principal list to create `GenesAndHealth_custombinary_codelist_v010_2025-04-22v1.csv`  \n",
    "\n",
    "The \"code\" to get the extra lines is in the `Code graveyard` below. \n",
    "\n",
    "**Note added by SR 2025-05-16**\n",
    "\n",
    "1. We added QOF `_COD` codesets pertaining to relevant primary care managed conditions (e.g. `QOF_CHD_COD` (Coronary heart disease), `QOF_AST_COD` (Asthma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tretools.datasets.demographic_dataset import DemographicDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_file_path = f\"{ROOT_LOCATION}/{VERSION}/processed_datasets/demographics/clean_demographics.arrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = DemographicDataset(path=demographic_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_demographics_standalone(lf: pl.LazyFrame, demographics: DemographicDataset) -> pl.LazyFrame:\n",
    "        print(\"STANDALONE _calculate_demographics (similar to that of tretools.counter.counter)\")\n",
    "        \n",
    "        gender_map = {1: \"M\", 2: \"F\"}\n",
    "\n",
    "        # Merge the first events data with demographics together\n",
    "        first_events_plus_demographics = (\n",
    "            lf\n",
    "            .join(\n",
    "                demographics.data.lazy(),\n",
    "                on=\"nhs_number\", \n",
    "                how=\"inner\"\n",
    "            )\n",
    "            .with_columns(\n",
    "                ((pl.col(\"date\") - pl.col(\"dob\")).dt.total_days() / 365.25)\n",
    "                .round(1)\n",
    "                .alias(\"age_at_event\")\n",
    "            )\n",
    "            .with_columns([\n",
    "                pl.col(\"age_at_event\").cut( # ?<16\n",
    "                    [16, 25, 35, 45, 55, 65, 75, 85], \n",
    "                    labels=[\"<16\", \"16-24\", \"25-34\", \"35-44\", \"45-54\", \"55-64\", \"65-74\", \"75-84\", \"85+\"]\n",
    "                )\n",
    "                .alias(\"age_range\"),\n",
    "                pl.col(\"gender\")\n",
    "                .replace_strict(gender_map)\n",
    "            ])\n",
    "#             .select(\n",
    "#                 pl.col(\"nhs_number\"), \n",
    "#                 pl.col(\"phenotype\"),\n",
    "#                 pl.col(\"code\"),\n",
    "#                 pl.col(\"term\"),\n",
    "#                 pl.col(\"coding_system\"),\n",
    "#                 pl.col(\"date\"), \n",
    "#                 pl.col(\"age_at_event\"), \n",
    "#                 pl.col(\"gender\"), \n",
    "#                 pl.col(\"age_range\")\n",
    "#             )\n",
    "        )\n",
    "\n",
    "#         self.log.append(f\"{datetime.now()}: Demographic data added to the report\")\n",
    "        return first_events_plus_demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mapped_combo = (\n",
    "    pl.concat(\n",
    "        [\n",
    "# We could, but do not, include ICD10 codes obtained via mapping of SNOMED for definition of the\n",
    "# custom phenotypes.  This is because we posit that if a valid ICD10 is obtained via mapping then\n",
    "# the original SNOMED ought to be part of the codelist (i.e. direct attribution not indirect attribution)\n",
    "#             (\n",
    "#\n",
    "#                 pl.scan_ipc(\n",
    "#                     f\"{MEGADATA_LOCATION}/icd_and_mapped_snomed.arrow\",\n",
    "#                 )\n",
    "#                 .with_columns(\n",
    "#                     pl.lit(\"ICD10\")\n",
    "#                     .cast(coding_system_enum)\n",
    "#                     .alias(\"coding_system\")\n",
    "#                 )\n",
    "#             ),\n",
    "            (\n",
    "                pl.scan_ipc(\n",
    "                    f\"{MEGADATA_LOCATION}/icd_only.arrow\",\n",
    "                )\n",
    "                .with_columns(\n",
    "                    pl.lit(\"ICD10\")\n",
    "                    .cast(coding_system_enum)\n",
    "                    .alias(\"coding_system\")\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                pl.scan_ipc(\n",
    "                    f\"{MEGADATA_LOCATION}/opcs_only.arrow\",\n",
    "                )\n",
    "                .with_columns(\n",
    "                    pl.lit(\"OPCS4\")\n",
    "                    .cast(coding_system_enum)\n",
    "                    .alias(\"coding_system\")\n",
    "                )\n",
    "            ),\n",
    "            (\n",
    "                pl.scan_ipc(\n",
    "                    f\"{MEGADATA_LOCATION}/snomed_only.arrow\",\n",
    "                )\n",
    "                .with_columns(\n",
    "                    pl.lit(\"SNOMED_ConceptID\")\n",
    "                    .cast(coding_system_enum)\n",
    "                    .alias(\"coding_system\"),\n",
    "                    pl.col(\"code\").cast(pl.Utf8)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "#     .with_columns(\n",
    "#         pl.len().over([\"nhs_number\", \"code\", \"date\"]).alias(\"dup_count\")\n",
    "#     )\n",
    "    .join(\n",
    "        custom_phenotype_mapping,\n",
    "        on=[\"code\", \"coding_system\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .group_by([\"nhs_number\", \"phenotype\"])\n",
    "    .agg(\n",
    "        pl.col(\"date\").min(),\n",
    "        pl.col(\"code\").explode().unique().alias(\"all_codes\"),\n",
    "        pl.col(\"coding_system\").explode().unique().alias(\"all_coding_systems\"),\n",
    "        pl.col(\"code\").filter(pl.col(\"date\") == pl.col(\"date\").min()).first().alias(\"code\"),\n",
    "        pl.col(\"term\").filter(pl.col(\"date\") == pl.col(\"date\").min()).first().alias(\"term\"),\n",
    "        \n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col(\"all_codes\").list.join(\" | \"),\n",
    "        pl.col(\"all_coding_systems\").cast(pl.List(pl.Utf8)).list.join(\" | \")\n",
    "    )\n",
    "    .sort([\"nhs_number\", \"date\", \"code\", ])\n",
    "    .pipe(_calculate_demographics_standalone, demographics=demographics)\n",
    "    .select(\n",
    "        pl.col('nhs_number'),\n",
    "        pl.col('phenotype'),\n",
    "        pl.col('date'),\n",
    "        pl.col('code'),\n",
    "        pl.col('term'),\n",
    "        pl.col('all_codes'),\n",
    "        pl.col('all_coding_systems'),\n",
    "        pl.col('gender'),\n",
    "        pl.col('dob'),\n",
    "        pl.col('age_at_event'),\n",
    "        pl.col('age_range'),\n",
    "    )\n",
    "#     .collect()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Partition by custom_phenotype\n",
    "custom_mapped_combo_phenotype_dict = (\n",
    "    custom_mapped_combo\n",
    "    .collect()\n",
    "    .partition_by(\n",
    "        \"phenotype\",\n",
    "        as_dict=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6cb1c",
   "metadata": {},
   "source": [
    "## Write individual custom phenotype (aka trait) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7de515f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# sorted for clarity, not efficiency\n",
    "for i, ((phenotype, ), df) in enumerate(sorted(custom_mapped_combo_phenotype_dict.items())):\n",
    "    print(f\"{i+1}. {phenotype}\", end=\", \")\n",
    "    (\n",
    "        df\n",
    "        .lazy()\n",
    "        .sink_csv(\n",
    "            AnyPath(\n",
    "                OUTPUTS_INDIVIDUAL_TRAIT_FILES_LOCATION,\n",
    "                f\"{yr}_{mon}_{phenotype}_summary_report.csv\"\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92e2299",
   "metadata": {},
   "source": [
    "## Create phenotype reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a5901",
   "metadata": {},
   "source": [
    "cf. version080 \n",
    "\n",
    "`.../custom_phenotypes/overall_summary_report_README.md`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf98dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_custom_phenotypes_count_summary(lf: pl.LazyFrame) -> None:\n",
    "    report_filename = f\"custom_phenotypes_count_summary.md\"\n",
    "    report_path = AnyPath(OUTPUTS_INDIVIDUAL_TRAIT_FILES_LOCATION, report_filename)\n",
    "    \n",
    "    df = (\n",
    "        lf\n",
    "        .select(\n",
    "            pl.col(\"phenotype\").value_counts()\n",
    "        )\n",
    "        .unnest(\"phenotype\")\n",
    "        .join(\n",
    "            custom_phenotype_mapping.select(pl.col(\"phenotype\").unique()),\n",
    "            on=\"phenotype\",\n",
    "            how=\"right\"\n",
    "        )\n",
    "        .sort(\"phenotype\")\n",
    "\n",
    "        .select(\n",
    "            pl.col(\"phenotype\"),\n",
    "            pl.col(\"count\").fill_null(0),\n",
    "        )\n",
    "        .collect()\n",
    "    )\n",
    "    \n",
    "    max_phenotype_char_length = df.select(pl.col(\"phenotype\").str.len_chars().max()).item()\n",
    "#     print(f\"max_phenotype_char_length: {max_phenotype_char_length}\")\n",
    "    \n",
    "    with open(report_path, \"w\") as f:\n",
    "        print(f\"\"\"# Custom Phenotype Count Summary Report\n",
    "\n",
    "## Generated by Genes and Health *BI_PY* pipeline\n",
    "\n",
    "Generated by the BI_PY `8-custom-phenotypes-individual-trait-files-and-regenie` notebook.\n",
    "\n",
    "## Report Generation Date and Time\n",
    "\n",
    "This report was generated at {datetime.today().strftime(format=\"%d %B %Y %H:%M:%S\")}.\n",
    " \n",
    "## Report Overview\n",
    "\n",
    "This summary report provides an overview of the counts associated with each phenotype across all datasets:\n",
    "\n",
    "- Discovery Primary Care\n",
    "- Barts Health\n",
    "- Bradford\n",
    "- NHS Digital\n",
    "\n",
    "## Summary\n",
    "\"\"\", file=f)\n",
    "\n",
    "    with pl.Config(\n",
    "        tbl_formatting=\"ASCII_MARKDOWN\",\n",
    "        tbl_hide_column_data_types=True,\n",
    "        tbl_hide_dataframe_shape=True,\n",
    "        tbl_cell_numeric_alignment=\"RIGHT\",\n",
    "        fmt_str_lengths=max_phenotype_char_length,\n",
    "        tbl_rows=-1,\n",
    "    ):\n",
    "        with open(report_path, \"a\") as f:\n",
    "            print(\n",
    "                df,\n",
    "                file=f\n",
    "            )\n",
    "    print(f\"Report `{report_filename}` generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9908c3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_custom_phenotypes_count_summary(lf=custom_mapped_combo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb26fc",
   "metadata": {},
   "source": [
    "# regenie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b1270",
   "metadata": {},
   "source": [
    "## Generate 55k ExWAS - regenie input file (i.e. not covariate file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_regenie_55k = (\n",
    "    pl.scan_csv(\n",
    "        MEGA_LINKAGE_PATH,\n",
    "        infer_schema=False,\n",
    "        new_columns=[\n",
    "            \"OrageneID\",\n",
    "            \"Number of OrageneIDs with this NHS number (i.e. taken part twice or more)\",\n",
    "            \"s1qst_gender\",\n",
    "            \"HasValidNHS\",\n",
    "            \"pseudo_nhs_number\",\n",
    "            \"gsa_id\",\n",
    "            \"44028exomes_release_2023-JUL-07\",\n",
    "            \"exome_id\",\n",
    "        ]\n",
    "    )\n",
    "    .TRE\n",
    "    .filter_with_logging(\n",
    "        pl.col(\"exome_id\").is_not_null(),\n",
    "        pl.col(\"pseudo_nhs_number\").is_not_null(), # there are some rows with NON-NULL exome_id but NULL pseudo_nhs_number\n",
    "        label=\"Only include NON-NULL exome_id and NON-NULL pseudo_nhs_number for 55k Regenie\"\n",
    "    )\n",
    "    .TRE\n",
    "    .filter_with_logging(\n",
    "        pl.col(\"OrageneID\").is_not_null(),\n",
    "        label=\"Sanity check to ensure no NULL OrageneID. row count should remain unchanged\"\n",
    "    )\n",
    "    .TRE\n",
    "    .unique_with_logging(\n",
    "        [\"pseudo_nhs_number\"],\n",
    "        label=\"Sanity check: row count should remain unchanged when uniquing by pseudo_nhs_number\"\n",
    "    )\n",
    "    .TRE\n",
    "    .unique_with_logging(\n",
    "        [\"OrageneID\"],\n",
    "        label=\"Sanity check: row count should remain unchanged when uniquing by OrageneID\"\n",
    "    )\n",
    "    .select(\n",
    "        pl.col(\"pseudo_nhs_number\"),\n",
    "        pl.col(\"exome_id\").alias(\"IID\")\n",
    "    )\n",
    "    .sort(by=\"IID\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96aa24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "combo_custom_phenotypes_55k_dict = (\n",
    "    custom_mapped_combo\n",
    "    .TRE\n",
    "    .join_with_logging(\n",
    "        valid_regenie_55k.select(\n",
    "            pl.col(\"pseudo_nhs_number\"),\n",
    "            pl.col(\"IID\"),\n",
    "        ),\n",
    "        left_on=\"nhs_number\",\n",
    "        right_on=\"pseudo_nhs_number\",\n",
    "        how=\"inner\",\n",
    "        label=\"restrict to pseudo_NHS_numbers with ExWAS\"\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.lit(\"1\").alias(\"FID\")\n",
    "    )\n",
    "    .select( ## We use the AgeAtFirstDiagnosis columns for covariate file generation later in pipeline\n",
    "        pl.col(\"FID\"),\n",
    "        pl.col(\"IID\"),\n",
    "        pl.col(\"phenotype\"),\n",
    "        pl.col(\"age_at_event\").round(1).alias(\"AgeAtFirstDiagnosis\"),\n",
    "        pl.col(\"age_at_event\").pow(2).round(1).alias(\"AgeAtFirstDiagnosis_Squared\"),\n",
    "    )\n",
    "    .sort(by=\"IID\")\n",
    "    .set_sorted(\"IID\")\n",
    "    .collect()\n",
    "    .partition_by(\n",
    "        \"phenotype\",\n",
    "        as_dict=True,\n",
    "        \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# [UPDATE: Fixed in Polars 1.26]. We have identifed possible bug with .sink_csv where header line separator is not changed to specified separator\n",
    "# i.e. header remains comma-separated while non-header rows are tab-delimited\n",
    "# We have found that if we use .write_csv instead, we work around this issue  \n",
    "# until we update polars for permanent fix.\n",
    "\n",
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            valid_regenie_55k\n",
    "            .with_columns(\n",
    "                pl.lit(\"1\")\n",
    "                .alias(\"FID\")\n",
    "            )\n",
    "            .select(\n",
    "                pl.col(\"FID\"),\n",
    "                pl.col(\"IID\")\n",
    "            ),\n",
    "            *[\n",
    "                valid_regenie_55k\n",
    "                .select(\n",
    "                    pl.col(\"IID\")\n",
    "                )\n",
    "                .join(\n",
    "                    lf\n",
    "                    .lazy(), \n",
    "                    on=\"IID\", \n",
    "                    how=\"left\"\n",
    "                )\n",
    "                .with_columns(\n",
    "                     pl.col(\"phenotype\")\n",
    "                    .is_not_null()\n",
    "                    .cast(pl.Int8)\n",
    "                    .cast(pl.Utf8)\n",
    "                    .alias(phenotype)\n",
    "                )\n",
    "                .select(\n",
    "                    pl.col(\"IID\"),\n",
    "                    pl.col(phenotype)\n",
    "                )\n",
    "\n",
    "                for (phenotype, ), lf in sorted(combo_custom_phenotypes_55k_dict.items())\n",
    "            ]\n",
    "        ],\n",
    "    how=\"align\"\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.sum_horizontal(\n",
    "            pl.all()\n",
    "            .exclude([\"FID\", \"IID\"])\n",
    "            .cast(pl.Int8, strict=False)\n",
    "        )\n",
    "        .alias(\"indv_pheno_count\")\n",
    "    )\n",
    "    .filter(pl.col(\"indv_pheno_count\")>0)\n",
    "    .select(\n",
    "        pl.exclude(\"indv_pheno_count\")\n",
    "    )\n",
    "    .sort(\"IID\")\n",
    "    .collect()  # see note above\n",
    "    .write_csv(  # see note above\n",
    "        AnyPath(\n",
    "            OUTPUTS_REGENIE_FILES_LOCATION,\n",
    "            f\"{yr}_{mon}_custom_phenotypes_regenie_55k_BroadExomeIDs.tsv\"\n",
    "        ),\n",
    "        separator=\"\\t\",\n",
    "        null_value=\"0\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d1fa19",
   "metadata": {},
   "source": [
    "## Generate 51k GWAS - regenie input file (i.e. not covariate file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_regenie_51k = (\n",
    "    pl.scan_csv(\n",
    "        MEGA_LINKAGE_PATH,\n",
    "        infer_schema=False,\n",
    "        new_columns=[\n",
    "            \"OrageneID\",\n",
    "            \"Number of OrageneIDs with this NHS number (i.e. taken part twice or more)\",\n",
    "            \"s1qst_gender\",\n",
    "            \"HasValidNHS\",\n",
    "            \"pseudo_nhs_number\",\n",
    "            \"gsa_id\",\n",
    "            \"44028exomes_release_2023-JUL-07\",\n",
    "            \"exome_id\",\n",
    "        ]\n",
    "    )\n",
    "    .TRE\n",
    "    .filter_with_logging(\n",
    "        pl.col(\"gsa_id\").is_not_null(),\n",
    "        pl.col(\"pseudo_nhs_number\").is_not_null(), # there are some rows with NON-NULL exome_id but NULL pseudo_nhs_number\n",
    "        label=\"Only include NON-NULL gsa_id and NON-NULL pseudo_nhs_number for 51k Regenie\"\n",
    "    )\n",
    "    .TRE\n",
    "    .filter_with_logging(\n",
    "        pl.col(\"OrageneID\").is_not_null(),\n",
    "        label=\"Sanity check to ensure no NULL OrageneID. row count should remain unchanged\"\n",
    "    )\n",
    "    .TRE\n",
    "    .unique_with_logging(\n",
    "        [\"pseudo_nhs_number\"],\n",
    "        label=\"Sanity check: row count should remain unchanged when uniquing by pseudo_nhs_number\"\n",
    "    )\n",
    "    .TRE\n",
    "    .unique_with_logging(\n",
    "        [\"OrageneID\"],\n",
    "        label=\"Sanity check: row count should remain unchanged when uniquing by OrageneID\"\n",
    "    )\n",
    "    .select(\n",
    "        pl.col(\"pseudo_nhs_number\"),\n",
    "        pl.col(\"gsa_id\").alias(\"IID\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "combo_custom_phenotypes_51k_dict = (\n",
    "    custom_mapped_combo\n",
    "    .TRE\n",
    "    .join_with_logging(\n",
    "        valid_regenie_51k.select(\n",
    "            pl.col(\"pseudo_nhs_number\"),\n",
    "            pl.col(\"IID\"),\n",
    "        ),\n",
    "        left_on=\"nhs_number\",\n",
    "        right_on=\"pseudo_nhs_number\",\n",
    "        how=\"inner\",\n",
    "        label=\"restrict to pseudo_NHS_numbers with GWAS\"\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.lit(\"1\").alias(\"FID\")\n",
    "    )\n",
    "    .select(\n",
    "        pl.col(\"FID\"),\n",
    "        pl.col(\"IID\"),\n",
    "        pl.col(\"phenotype\"),\n",
    "        pl.col(\"age_at_event\").round(1).alias(\"AgeAtFirstDiagnosis\"),\n",
    "        pl.col(\"age_at_event\").pow(2).round(1).alias(\"AgeAtFirstDiagnosis_Squared\"),\n",
    "    )\n",
    "    .sort(by=\"IID\")\n",
    "    .set_sorted(\"IID\")\n",
    "    .collect()\n",
    "    .partition_by(\n",
    "        \"phenotype\",\n",
    "        as_dict=True,\n",
    "        \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8038c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# [UPDATE: Fixed in Polars 1.26]. We have identifed possible bug with .sink_csv where header line separator is not changed to specified separator\n",
    "# i.e. header remains comma-separated while non-header rows are tab-delimited\n",
    "# We have found that if we use .write_csv instead, we work around this issue  \n",
    "# until we update polars for permanent fix.\n",
    "\n",
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            valid_regenie_51k\n",
    "            .with_columns(\n",
    "                pl.lit(\"1\")\n",
    "                .alias(\"FID\")\n",
    "            )\n",
    "            .select(\n",
    "                pl.col(\"FID\"),\n",
    "                pl.col(\"IID\")\n",
    "            ),\n",
    "            *[\n",
    "                valid_regenie_51k\n",
    "                .select(\n",
    "                    pl.col(\"IID\")\n",
    "                )\n",
    "                .join(\n",
    "                    lf\n",
    "                    .lazy(), \n",
    "                    on=\"IID\", \n",
    "                    how=\"left\"\n",
    "                )\n",
    "                .with_columns(\n",
    "                     pl.col(\"phenotype\")\n",
    "                    .is_not_null()\n",
    "                    .cast(pl.Int8)\n",
    "                    .cast(pl.Utf8)\n",
    "                    .alias(phenotype)\n",
    "                )\n",
    "                .select(\n",
    "                    pl.col(\"IID\"),\n",
    "                    pl.col(phenotype)\n",
    "                )\n",
    "\n",
    "                for (phenotype, ), lf in sorted(combo_custom_phenotypes_51k_dict.items())\n",
    "            ]\n",
    "        ],\n",
    "    how=\"align\"\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.sum_horizontal(\n",
    "            pl.all()\n",
    "            .exclude([\"FID\", \"IID\"])\n",
    "            .cast(pl.Int8, strict=False)\n",
    "        )\n",
    "        .alias(\"indv_pheno_count\")\n",
    "    )\n",
    "    .filter(pl.col(\"indv_pheno_count\")>0)\n",
    "    .select(\n",
    "        pl.exclude(\"indv_pheno_count\")\n",
    "    )\n",
    "    .sort(\"IID\")\n",
    "    .collect()  # see note above\n",
    "    .write_csv(  # see note above\n",
    "        AnyPath(\n",
    "            OUTPUTS_REGENIE_FILES_LOCATION,\n",
    "            f\"{yr}_{mon}_custom_phenotypes_regenie_51koct2024_65A_Topmed.tsv\"\n",
    "        ),\n",
    "        separator=\"\\t\",\n",
    "        null_value=\"0\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fca1394",
   "metadata": {},
   "source": [
    "## Now generate covariate files (AgeAtFirstDiagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d06f52",
   "metadata": {},
   "source": [
    "## 55k ExWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d479b68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# [UPDATE: Fixed in Polars 1.26]. We have identifed possible bug with .sink_csv where header line separator is not changed to specified separator\n",
    "# i.e. header remains comma-separated while non-header rows are tab-delimited\n",
    "# We have found that if we use .write_csv instead, we work around this issue  \n",
    "# until we update polars for permanent fix.\n",
    "\n",
    "# temp_cov_55k = (\n",
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            valid_regenie_55k\n",
    "            .with_columns(\n",
    "                pl.lit(\"1\")\n",
    "                .alias(\"FID\")\n",
    "            )\n",
    "            .select(\n",
    "                pl.col(\"FID\"),\n",
    "                pl.col(\"IID\")\n",
    "            ),\n",
    "            *[\n",
    "                valid_regenie_55k\n",
    "                .select(\n",
    "                    pl.col(\"IID\"),\n",
    "                )\n",
    "                .join(\n",
    "                    lf\n",
    "                    .lazy()\n",
    "                    .select(\n",
    "                        pl.col(\"IID\"),\n",
    "                        pl.col(\"AgeAtFirstDiagnosis\").alias(f\"AgeAtFirstDiagnosis.{phenotype}\"),\n",
    "                        pl.col(\"AgeAtFirstDiagnosis_Squared\").alias(f\"AgeAtFirstDiagnosis_Squared.{phenotype}\")\n",
    "                    ), \n",
    "                    on=\"IID\", \n",
    "                    how=\"left\"\n",
    "                )\n",
    "\n",
    "                for (phenotype, ), lf in sorted(combo_custom_phenotypes_55k_dict.items())\n",
    "            ],\n",
    "        ],\n",
    "    how=\"align\"\n",
    "    )\n",
    "    .with_columns(\n",
    "            (\n",
    "                pl.sum_horizontal(\n",
    "                    pl.all()\n",
    "                    .exclude([\"FID\", \"IID\"])\n",
    "                    .is_not_null()\n",
    "                )\n",
    "                .cast(pl.Boolean)\n",
    "                .alias(\"indv_has_ge_1_phenotypes\")\n",
    "            )\n",
    "    )\n",
    "    .sort(\"IID\")\n",
    "    .filter(\n",
    "        pl.col(\"indv_has_ge_1_phenotypes\")\n",
    "    )\n",
    "    .collect()  # see note above\n",
    "    .write_csv(  # see note above\n",
    "        AnyPath(\n",
    "            OUTPUTS_REGENIE_FILES_LOCATION,\n",
    "            f\"{yr}_{mon}_regenie_55k_BroadExomeIDs_Binary_custom_phenotypes_age_at_first_diagnosis_megawide.tsv\"\n",
    "        ),\n",
    "        separator=\"\\t\",\n",
    "        null_value=\"0\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd2961",
   "metadata": {},
   "source": [
    "## 51k GWAS covariate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ea0bfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# [UPDATE: Fixed in Polars 1.26]. We have identifed possible bug with .sink_csv where header line separator is not changed to specified separator\n",
    "# i.e. header remains comma-separated while non-header rows are tab-delimited\n",
    "# We have found that if we use .write_csv instead, we work around this issue  \n",
    "# until we update polars for permanent fix.\n",
    "\n",
    "# temp_cov_51k = (\n",
    "(\n",
    "    pl.concat(\n",
    "        [\n",
    "            valid_regenie_51k\n",
    "            .with_columns(\n",
    "                pl.lit(\"1\")\n",
    "                .alias(\"FID\")\n",
    "            )\n",
    "            .select(\n",
    "                pl.col(\"FID\"),\n",
    "                pl.col(\"IID\")\n",
    "            ),\n",
    "            *[\n",
    "                valid_regenie_51k\n",
    "                .select(\n",
    "                    pl.col(\"IID\"),\n",
    "                )\n",
    "                .join(\n",
    "                    lf\n",
    "                    .lazy()\n",
    "                    .select(\n",
    "                        pl.col(\"IID\"),\n",
    "                        pl.col(\"AgeAtFirstDiagnosis\").alias(f\"AgeAtFirstDiagnosis.{phenotype}\"),\n",
    "                        pl.col(\"AgeAtFirstDiagnosis_Squared\").alias(f\"AgeAtFirstDiagnosis_Squared.{phenotype}\")\n",
    "                    ), \n",
    "                    on=\"IID\", \n",
    "                    how=\"left\"\n",
    "                )\n",
    "\n",
    "                for (phenotype, ), lf in sorted(combo_custom_phenotypes_51k_dict.items())\n",
    "            ],\n",
    "        ],\n",
    "    how=\"align\"\n",
    "    )\n",
    "    .with_columns(\n",
    "            (\n",
    "                pl.sum_horizontal(\n",
    "                    pl.all()\n",
    "                    .exclude([\"FID\", \"IID\"])\n",
    "                    .is_not_null()\n",
    "                )\n",
    "                .cast(pl.Boolean)\n",
    "                .alias(\"indv_has_ge_1_phenotypes\")\n",
    "            )\n",
    "    )\n",
    "    .sort(\"IID\")\n",
    "    .filter(\n",
    "        pl.col(\"indv_has_ge_1_phenotypes\")\n",
    "    )\n",
    "    .collect()  # see note above\n",
    "    .write_csv(  # see note above\n",
    "        AnyPath(\n",
    "            OUTPUTS_REGENIE_FILES_LOCATION,\n",
    "            f\"{yr}_{mon}_regenie_51koct2024_65A_Topmed_Binary_custom_phenotypes_age_at_first_diagnosis_megawide.tsv\"\n",
    "        ),\n",
    "        separator=\"\\t\",\n",
    "        null_value=\"0\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8c7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"That's all folks!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b90afb",
   "metadata": {},
   "source": [
    "### Run next cell to initiate next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a904447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redirect_to_next_notebook_in_pipeline(\"change_to_next_notebook_if_applicable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e611116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
